# Autonomous and Alive: Kim Asendorf on his new work COLORS OF NOISE

### The German visual artist speaks with curator Peggy Schoenegge about shades of noise, the role of the algorithm, and working with sound.

### **[Visit the exhibition](https://feralfile.com/exhibitions) on Feral File.**

![](https://hackmd.io/_uploads/SkD5TDzB3.png)<caption>Still from “COLORS OF NOISE” by Kim Asendorf</caption>

**To start, can you explain your new work COLORS OF NOISE?**

I’m very much fascinated by the power of noise, something that’s universal and has been studied scientifically in different ways. In audio engineering, you can actually split up the full spectrum of noise — which is called white noise — into various shades, which are named by colors, such as pink noise, brown noise, and white noise. With this work, I use these different shades of acoustic noise to drive a visual animation.

With my work in general, I work a lot with visual feedback to create animations that feel autonomous and alive, and very detailed when it comes to the movement of singular pixels. Usually, with these kinds of animations, I use noise algorithms that are based on [Perlin noise](https://www.khanacademy.org/computing/computer-programming/programming-natural-simulations/programming-noise/a/perlin-noise), which is a high performance algorithm, but is in itself quite complex.

For COLORS OF NOISE, I was thinking instead about using an acoustic noise stream, which is more or less just random numbers, but when you turn them into some kind of acoustic output, it becomes very widespread over the spectrum of noise. I wanted to replace the common noise algorithms I use for visual work with the noise that is really acoustic noise.

![](https://hackmd.io/_uploads/HkI1AvGrn.png)<caption>Still from “COLORS OF NOISE” by Kim Asendorf</caption>

**So maybe a good analogy is that this work is like a visual transformation of a sound we hear, instead of creating a representative of it, which is what you’ve done with previous work?**

More or less. I mean, most audio-reactive or audiovisual work is some kind of visualization of the music. But this is, of course, a bit difficult for noise, because you don't have events or anchors or happenings, or really any variation — it's like a straight signal. So this work was an experiment to see if I could visualize noise. What I'm really doing is having algorithms generate the noise acoustically, and I use the wave form of it — the wave shape, which is basically showing the current value of the audio — which is displayed in the center of the screen, triggering some kind of reaction around it. 

So if you collect the work COLORS OF NOISE, you’ll press the play button, and it will play back the noise through your speakers. The wave shape is used as a very small line in the middle of the animation that will trigger the animation, and it varies more or less with each color of noise. So if the noise is pretty high in its frequency, the wave shape is represented as very fast and sparkly, while with slower noises it feels more stretched and less detailed.

![](https://hackmd.io/_uploads/HJ-MAPMHn.png)<caption>Still from “COLORS OF NOISE” by Kim Asendorf</caption>

**So we have this connection to the wave line of the sound, but then it spreads to the top and bottom of the screen, creating the visual. In that process, it kind of becomes its own work as it forms an abstract, black-and-white visuality that is also reminding us of a moiré pattern, well known from OP art. The sound gives an input, or a starting point, but then it transforms into something of its own, even though it is connected to the sound.**

Yeah, I really use the noise more as a trigger. The animations that arise above and below it are each its own algorithm, which gets triggered by the central wave shape. It's really a collection of animations that need an input, which is the noise in this case.

**I was wondering about the role of the algorithm in your work in general. You work a lot with these kinds of rigorous instructions. Why did you decide to integrate them into your artistic process? And, with this work in particular, why use algorithms to create both noise, on the one hand, and visuality, on the other? Why did you not just animate or generate these on your own?**

I could have prerecorded or used any other tool to create these noises and just worked with a set of samples or something like that. But I really like that the work in itself can be completely self-contained and doesn't need any assets. It is therefore very compact in its code-based size and total file size and can basically live on its own in this very light way. That aspect is inspired by the [demoscene](http://demoscene-the-art-of-coding.net/the-demoscene/), where people create artworks that are just 60 or even six kilobytes in size and completely self-contained.

![](https://hackmd.io/_uploads/By200PzH3.png)<caption>Still from “COLORS OF NOISE” by Kim Asendorf</caption>

**You built the system, but then the system runs on its own, almost creating the impression that the work is its own entity. The other interesting thing is that it forms something ephemeral, right? Since the algorithm won't repeat itself.**

Right, it’s not a recording, so it will not loop. But since noise is something quite steady in its appearance, it's more or less a steady stream. All the animations have also been designed to become a stream of, in this case, pixels, which are flowing up and down, but pretty steadily. Nonetheless, the details will never repeat exactly. 

The whole COLORS OF NOISE series has been handpicked, so it's not completely random which noise or which animation goes with which sound. There were theoretically a bunch of possibilities, but I really had the feeling that some colors of noise — some sounds — go much better with certain animations. So each piece is really a handmade composition.

### **[Visit the exhibition](https://feralfile.com/exhibitions) on Feral File.**
